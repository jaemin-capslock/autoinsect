{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from kerastuner.engine.hypermodel import HyperModel\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.tuners.randomsearch import RandomSearch\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data_dir = \"D://Betastop_dataset/insect_dataset/_train\"\n",
    "train_data_dir = pathlib.Path(train_data_dir)\n",
    "image_count = len(list(train_data_dir.glob('*/*.jpg')) + list(train_data_dir.glob('*/*.jpeg')))\n",
    "print(image_count)\n",
    "\n",
    "validation_data_dir = \"D://Betastop_dataset/insect_dataset/_validation\"\n",
    "validation_data_dir = pathlib.Path(validation_data_dir)\n",
    "\n",
    "test_data_dir = \"D://Betastop_dataset/insect_dataset/_test\"\n",
    "test_data_dir = pathlib.Path(test_data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_list_ds = tf.data.Dataset.list_files(str(train_data_dir/'*/*'))\n",
    "for f in train_list_ds.take(5):\n",
    "    print(f.numpy())\n",
    "validation_list_ds = tf.data.Dataset.list_files(str(validation_data_dir/'*/*'))\n",
    "test_list_ds = tf.data.Dataset.list_files(str(test_data_dir/'*/*'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in train_data_dir.glob('*')])\n",
    "import os\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2] == CLASS_NAMES\n",
    "\n",
    "print(str(CLASS_NAMES))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  print(label[0])\n",
    "  return img, label\n",
    "train_labeled_ds = train_list_ds.map(process_path, num_parallel_calls = 8)\n",
    "validation_labeled_ds = validation_list_ds.map(process_path, num_parallel_calls = 8)\n",
    "test_labeled_ds = test_list_ds.map(process_path, num_parallel_calls=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for image, label in train_labeled_ds.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())\n",
    "\n",
    "test_label_list = []\n",
    "for image, label in test_labeled_ds.take(-1):\n",
    "    test_label_list.append(label.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "  # This is a small dataset, only load it once, and keep it in memory.\n",
    "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "  # fit in memory.\n",
    "  if cache:\n",
    "    if isinstance(cache, str):\n",
    "      ds = ds.cache(cache)\n",
    "    else:\n",
    "      ds = ds.cache()\n",
    "\n",
    "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "  # Repeat forever\n",
    "  ds = ds.repeat()\n",
    "\n",
    "  ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "  # is training.\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "  return ds\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "train_ds = prepare_for_training(train_labeled_ds, cache = './train.tfcache')\n",
    "\n",
    "\n",
    "validation_ds = prepare_for_training(validation_labeled_ds, cache = './val.tfcache')\n",
    "\n",
    "test_ds = prepare_for_training(test_labeled_ds, cache = './test.tfcache')\n",
    "\n",
    "print(test_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from progress.bar import Bar\n",
    "label_list = []\n",
    "\n",
    "alpha, beta = next(iter(test_ds))\n",
    "a = beta.numpy()\n",
    "\n",
    "a = a.astype(int)\n",
    "print(a)\n",
    "print(a[5])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_list = []\n",
    "for image, label in test_ds.take(152):\n",
    "    label_list.append(label.numpy())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from focal_loss import SparseCategoricalFocalLoss\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\",\n",
    "                        trainable = False))\n",
    "model.add(keras.layers.Dropout(rate=0.3))\n",
    "model.add(keras.layers.Dense(40, activation = \"softmax\"))\n",
    "model.build([None, 224, 224, 3])\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              loss = keras.losses.categorical_crossentropy,\n",
    "              metrics = ['accuracy', tfa.metrics.CohenKappa(num_classes=40), tfa.metrics.F1Score(num_classes=40), keras.metrics.TrueNegatives(), keras.metrics.TruePositives(),\n",
    "                         keras.metrics.FalseNegatives(), keras.metrics.FalsePositives()])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#history = model.fit(train_ds,\n",
    "          #steps_per_epoch=np.round(image_count/BATCH_SIZE) - 1,\n",
    "          #epochs = 20,\n",
    "          #validation_data= validation_ds,\n",
    "          #validation_steps= 30)\n",
    "\n",
    "predicted_list = model.predict(test_ds, batch_size=32, steps=152, verbose = 1)\n",
    "\n",
    "print(predicted_list.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print(predicted_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_label_list = np.asarray(test_label_list)\n",
    "print(test_label_list.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sklearn\n",
    "label_list = np.asarray(label_list)\n",
    "label_list = label_list.astype(int)\n",
    "label_list = label_list.reshape((4864, 40))\n",
    "print(label_list[1340])\n",
    "print(predicted_list[1340])\n",
    "\n",
    "hello = sklearn.metrics.roc_auc_score(label_list, predicted_list, average='micro', multi_class='ovr')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(hello)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(test_ds, steps=152)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}